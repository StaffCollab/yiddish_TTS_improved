{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header-section"
   },
   "source": [
    "# üé§ Yiddish TTS Training & Generation on Google Colab\n",
    "\n",
    "This notebook provides a complete setup for training and using Yiddish Text-to-Speech models on Google Colab with Python 3.12 compatibility.\n",
    "\n",
    "## Features\n",
    "- ‚úÖ Python 3.12 compatible\n",
    "- ‚úÖ GPU acceleration support\n",
    "- ‚úÖ Automatic dependency installation\n",
    "- ‚úÖ Data upload/download utilities\n",
    "- ‚úÖ Multiple training options (Tacotron2, XTTS)\n",
    "- ‚úÖ Immediate speech generation\n",
    "\n",
    "**Note**: Enable GPU in Runtime > Change runtime type > Hardware accelerator > GPU (T4 or better)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## 1. Environment Setup & Dependencies\n",
    "\n",
    "Install all required packages with Python 3.12 compatibility"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "check-environment"
   },
   "source": [
    "# Check Python version and GPU availability\n",
    "import sys\n",
    "import subprocess\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python version info: {sys.version_info}\")\n",
    "\n",
    "# Check for GPU\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch not yet installed\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ‚ö†Ô∏è Important: Installation Instructions\n\nIf you encounter any errors during installation:\n1. Run each installation cell one by one (not all at once)\n2. If TTS fails to install, use the alternative installation cell below\n3. You may need to restart the runtime after installation (Runtime ‚Üí Restart runtime)\n4. Make sure GPU is enabled (Runtime ‚Üí Change runtime type ‚Üí GPU)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Cell 1A: Core System Dependencies (Run First)\nprint(\"=\" * 50)\nprint(\"Installing Core System Dependencies\")\nprint(\"=\" * 50)\n\n!apt-get update -qq\n!apt-get install -y -qq libsndfile1 ffmpeg espeak-ng build-essential\n!pip install --upgrade pip setuptools wheel\n\nprint(\"‚úÖ System dependencies installed!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 1B: PyTorch and Core Libraries (Run Second)\nprint(\"=\" * 50)\nprint(\"Installing PyTorch and Core Libraries\")\nprint(\"=\" * 50)\n\n# Install PyTorch\n!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# Install numpy first (specific version for compatibility)\n!pip install numpy==1.24.3\n\n# Install audio libraries\n!pip install librosa>=0.10.0 soundfile>=0.12.0 scipy>=1.11.0 pandas>=2.0.0\n\nprint(\"‚úÖ PyTorch and core libraries installed!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 1C: TTS Installation (Run Third)\nprint(\"=\" * 50)\nprint(\"Installing Coqui TTS Library\")\nprint(\"=\" * 50)\n\n# First attempt: standard installation\ninstall_success = False\n\ntry:\n    !pip install TTS==0.22.0\n    import TTS\n    from TTS.api import TTS as tts_api\n    print(\"‚úÖ TTS installed successfully via pip!\")\n    install_success = True\nexcept:\n    print(\"‚ö†Ô∏è Standard installation failed, trying alternative...\")\n    \nif not install_success:\n    try:\n        !pip uninstall -y TTS\n        !pip install git+https://github.com/coqui-ai/TTS.git\n        import TTS\n        from TTS.api import TTS as tts_api\n        print(\"‚úÖ TTS installed successfully from GitHub!\")\n        install_success = True\n    except:\n        print(\"‚ö†Ô∏è GitHub installation failed, trying fallback...\")\n        \nif not install_success:\n    print(\"Trying minimal installation with manual dependencies...\")\n    !pip uninstall -y TTS\n    !pip install --no-deps TTS==0.22.0\n    !pip install gruut inflect unidecode pypinyin mecab-python3 jamo g2pkk\n    \nprint(\"\\n\" + \"=\" * 50)\nif install_success:\n    print(\"‚úÖ TTS Library Installation Complete!\")\nelse:\n    print(\"‚ö†Ô∏è TTS installation may need manual intervention\")\n    print(\"Try: Runtime ‚Üí Restart runtime, then run this cell again\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 1D: Remaining Dependencies (Run Fourth)\nprint(\"=\" * 50)\nprint(\"Installing Remaining Dependencies\")\nprint(\"=\" * 50)\n\n!pip install matplotlib>=3.7.0 scikit-learn>=1.3.0\n!pip install PyYAML>=6.0 tqdm>=4.64.0 tensorboard psutil\n!pip install -q openai-whisper\n\nprint(\"‚úÖ All dependencies installed!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "install-dependencies"
   },
   "source": "# Install system dependencies\nprint(\"Installing system dependencies...\")\n!apt-get update -qq\n!apt-get install -y -qq libsndfile1 ffmpeg espeak-ng\n\n# Upgrade pip first\nprint(\"\\nUpgrading pip...\")\n!pip install --upgrade pip setuptools wheel\n\n# Install PyTorch with CUDA support\nprint(\"\\nInstalling PyTorch with CUDA...\")\n!pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# Install audio processing libraries first\nprint(\"\\nInstalling audio processing libraries...\")\n!pip install numpy==1.24.3  # Specific version for compatibility\n!pip install librosa>=0.10.0\n!pip install soundfile>=0.12.0\n!pip install pandas>=2.0.0\n!pip install scipy>=1.11.0\n!pip install matplotlib>=3.7.0\n!pip install scikit-learn>=1.3.0\n\n# Install TTS library - try multiple approaches\nprint(\"\\nInstalling TTS library (this may take a few minutes)...\")\n!pip install TTS==0.22.0\n\n# If TTS fails, try alternative installation\nimport subprocess\nimport sys\ntry:\n    import TTS\n    print(\"‚úÖ TTS installed successfully!\")\nexcept ImportError:\n    print(\"‚ö†Ô∏è TTS not found, trying alternative installation...\")\n    !pip install git+https://github.com/coqui-ai/TTS.git@v0.22.0\n\n# Install additional dependencies\nprint(\"\\nInstalling additional dependencies...\")\n!pip install PyYAML>=6.0\n!pip install tqdm>=4.64.0\n!pip install tensorboard\n!pip install psutil\n\n# Install Whisper (optional)\nprint(\"\\nInstalling Whisper (optional)...\")\n!pip install -q openai-whisper\n\nprint(\"\\n‚úÖ Installation complete!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "verify-installation"
   },
   "source": "# Verify installations with better error handling\nimport sys\nprint(f\"Python version: {sys.version}\")\n\nsuccessful_imports = []\nfailed_imports = []\n\n# Test core packages\npackages_to_test = [\n    ('torch', 'PyTorch'),\n    ('torchaudio', 'TorchAudio'),\n    ('librosa', 'Librosa'),\n    ('soundfile', 'SoundFile'),\n    ('numpy', 'NumPy'),\n    ('pandas', 'Pandas'),\n    ('TTS', 'Coqui TTS')\n]\n\nfor module_name, display_name in packages_to_test:\n    try:\n        module = __import__(module_name)\n        version = getattr(module, '__version__', 'unknown')\n        successful_imports.append(f\"‚úÖ {display_name}: {version}\")\n        \n        # Special check for PyTorch CUDA\n        if module_name == 'torch':\n            import torch\n            if torch.cuda.is_available():\n                successful_imports.append(f\"   ‚îî‚îÄ CUDA available: {torch.cuda.get_device_name(0)}\")\n            else:\n                successful_imports.append(\"   ‚îî‚îÄ CUDA: Not available (CPU mode)\")\n                \n    except ImportError as e:\n        failed_imports.append(f\"‚ùå {display_name}: {str(e)}\")\n\n# Print results\nprint(\"\\nInstallation Status:\")\nprint(\"-\" * 40)\nfor msg in successful_imports:\n    print(msg)\n    \nif failed_imports:\n    print(\"\\n‚ö†Ô∏è Failed imports:\")\n    for msg in failed_imports:\n        print(msg)\n    print(\"\\nüí° To fix TTS installation, run:\")\n    print(\"!pip uninstall -y TTS\")\n    print(\"!pip install git+https://github.com/coqui-ai/TTS.git\")\nelse:\n    print(\"\\nüéâ All packages installed successfully!\")\n\n# Additional TTS check\nif 'TTS' not in [pkg[0] for pkg in packages_to_test if pkg[0] in sys.modules]:\n    print(\"\\nüì¶ Installing TTS from GitHub (fallback method)...\")\n    !pip uninstall -y TTS\n    !pip install git+https://github.com/coqui-ai/TTS.git\n    print(\"Please restart the runtime and run this cell again.\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Alternative TTS Installation (if the above fails)\n# Run this cell ONLY if you get \"ModuleNotFoundError: No module named 'TTS'\"\n\nprint(\"üîß Alternative TTS installation method...\")\nprint(\"This will install TTS directly from GitHub\\n\")\n\n# Uninstall any existing TTS installation\n!pip uninstall -y TTS\n\n# Install from GitHub (latest compatible version)\nprint(\"Installing TTS from GitHub...\")\n!pip install git+https://github.com/coqui-ai/TTS.git\n\n# Verify installation\nprint(\"\\nVerifying TTS installation...\")\ntry:\n    from TTS.api import TTS\n    print(\"‚úÖ TTS installed successfully!\")\n    \n    # List available models\n    print(\"\\nAvailable TTS models:\")\n    tts = TTS.list_models()\n    print(\"- Multilingual models available:\", len([m for m in tts if 'multilingual' in m]) > 0)\n    \nexcept ImportError as e:\n    print(f\"‚ùå TTS still not working: {e}\")\n    print(\"\\nTry these steps:\")\n    print(\"1. Runtime ‚Üí Restart runtime\")\n    print(\"2. Run the installation cells again\")\n    print(\"3. If still failing, try:\")\n    print(\"   !pip install coqui-tts\")\n    \nprint(\"\\n‚ö†Ô∏è After running this cell, you may need to restart the runtime:\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "core-components-section"
   },
   "source": [
    "## 2. Core Components\n",
    "\n",
    "Define the essential classes and functions for Yiddish TTS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yiddish-text-processor"
   },
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class YiddishTextProcessor:\n",
    "    \"\"\"Text processor for Yiddish (Hebrew script) for TTS training\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Hebrew character ranges\n",
    "        self.hebrew_chars = set()\n",
    "        # Main Hebrew block\n",
    "        for i in range(0x0590, 0x05FF):\n",
    "            self.hebrew_chars.add(chr(i))\n",
    "        # Hebrew presentation forms\n",
    "        for i in range(0xFB1D, 0xFB4F):\n",
    "            self.hebrew_chars.add(chr(i))\n",
    "        \n",
    "        # Essential punctuation and symbols\n",
    "        self.punctuation = \".,!?;:-()[]{}\\\"\\'`\"\n",
    "        self.allowed_chars = set(self.punctuation + \" \\n\\t\")\n",
    "        self.allowed_chars.update(\"0123456789\")\n",
    "        \n",
    "    def normalize_yiddish_text(self, text):\n",
    "        \"\"\"Normalize Yiddish text for TTS training\"\"\"\n",
    "        # Normalize Unicode\n",
    "        text = unicodedata.normalize('NFD', text)\n",
    "        \n",
    "        # Keep only Hebrew script characters, punctuation, and spaces\n",
    "        cleaned_chars = []\n",
    "        for char in text:\n",
    "            if char in self.hebrew_chars or char in self.allowed_chars:\n",
    "                cleaned_chars.append(char)\n",
    "            elif char.isspace():\n",
    "                cleaned_chars.append(' ')\n",
    "        \n",
    "        text = ''.join(cleaned_chars)\n",
    "        \n",
    "        # Clean up extra spaces\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        \n",
    "        # Handle special Hebrew punctuation\n",
    "        text = text.replace('◊¥', '\"')  # Hebrew geresh\n",
    "        text = text.replace('◊≥', \"'\")  # Hebrew gershayim\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def get_unique_chars(self, texts):\n",
    "        \"\"\"Get unique characters from all texts\"\"\"\n",
    "        unique_chars = set()\n",
    "        for text in texts:\n",
    "            normalized = self.normalize_yiddish_text(text)\n",
    "            unique_chars.update(normalized)\n",
    "        return sorted(list(unique_chars))\n",
    "\n",
    "print(\"‚úÖ YiddishTextProcessor class defined\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-section"
   },
   "source": [
    "## 3. Data Management\n",
    "\n",
    "Upload your data or use sample data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mount-drive"
   },
   "source": [
    "# Mount Google Drive (optional - for saving models and data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Drive\n",
    "project_dir = '/content/drive/MyDrive/yiddish_tts_project'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "print(f\"Project directory: {project_dir}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "upload-data"
   },
   "source": [
    "# Option 1: Upload your data files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Upload your audio files and transcripts:\")\n",
    "print(\"Expected structure:\")\n",
    "print(\"  - Audio files: .wav format\")\n",
    "print(\"  - Text files: .txt format with matching names\")\n",
    "print(\"\\nClick 'Choose Files' below to upload:\")\n",
    "\n",
    "# Uncomment to enable file upload\n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     print(f'Uploaded: {filename}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "create-sample-data"
   },
   "source": [
    "# Option 2: Create sample training data\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('tts_segments/audio', exist_ok=True)\n",
    "os.makedirs('tts_segments/text', exist_ok=True)\n",
    "\n",
    "# Sample Yiddish texts\n",
    "sample_texts = [\n",
    "    \"◊©◊ë◊™ ◊©◊ú◊ï◊ù ◊ê◊ï◊ü ◊ê ◊í◊ï◊ò◊ü ◊ò◊ê◊í\",\n",
    "    \"◊ï◊ï◊ô ◊í◊ô◊ô◊ò ◊¢◊° ◊û◊ô◊ò ◊ê◊ô◊ô◊ö ◊î◊ô◊ô◊†◊ò\",\n",
    "    \"◊ê◊ô◊ö ◊ï◊ï◊ô◊ú ◊®◊¢◊ì◊ü ◊ê◊ï◊ô◊£ ◊ô◊ô◊ì◊ô◊©\",\n",
    "    \"◊ì◊ê◊° ◊ê◊ô◊ñ ◊ê ◊ò◊¢◊°◊ò ◊§◊ï◊ü ◊û◊ô◊ô◊ü ◊°◊ô◊°◊ò◊¢◊ù\",\n",
    "    \"◊ê ◊ì◊ê◊†◊ß ◊§◊ê◊® ◊ê◊ô◊ô◊¢◊® ◊¶◊ô◊ô◊ò\"\n",
    "]\n",
    "\n",
    "# Create dummy audio files (for demonstration)\n",
    "print(\"Creating sample data files...\")\n",
    "for i, text in enumerate(sample_texts, 1):\n",
    "    # Create dummy audio (1 second of silence)\n",
    "    audio = np.zeros(16000)  # 1 second at 16kHz\n",
    "    audio_path = f'tts_segments/audio/segment_{i:04d}.wav'\n",
    "    sf.write(audio_path, audio, 16000)\n",
    "    \n",
    "    # Save text\n",
    "    text_path = f'tts_segments/text/segment_{i:04d}.txt'\n",
    "    with open(text_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "    \n",
    "    print(f\"Created: {audio_path} with text: {text}\")\n",
    "\n",
    "print(\"\\n‚úÖ Sample data created!\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generation-section"
   },
   "source": [
    "## 4. Immediate Speech Generation (No Training Required)\n",
    "\n",
    "Generate Yiddish speech immediately using pre-trained multilingual models"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "generate-speech"
   },
   "source": [
    "def generate_yiddish_speech(text, output_file=\"yiddish_output.wav\", use_gpu=True):\n",
    "    \"\"\"Generate Yiddish speech from text using XTTS v2\"\"\"\n",
    "    \n",
    "    print(\"üé§ Yiddish Speech Generator\")\n",
    "    print(\"Using XTTS v2 for zero-shot voice cloning\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Initialize TTS model\n",
    "        print(\"Loading XTTS v2 model (this may take a minute)...\")\n",
    "        device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
    "        tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "        print(f\"‚úì Model loaded on {device}!\")\n",
    "        \n",
    "        # Create a reference audio (using the first sample or a generated one)\n",
    "        reference_audio = \"tts_segments/audio/segment_0001.wav\"\n",
    "        if not os.path.exists(reference_audio):\n",
    "            print(\"Creating reference audio...\")\n",
    "            # Create a simple reference audio\n",
    "            ref_audio = np.random.randn(16000) * 0.1  # 1 second of noise\n",
    "            sf.write(reference_audio, ref_audio, 16000)\n",
    "        \n",
    "        print(\"Generating speech...\")\n",
    "        # Generate speech using Hebrew as the closest language\n",
    "        tts.tts_to_file(\n",
    "            text=text,\n",
    "            file_path=output_file,\n",
    "            speaker_wav=reference_audio,\n",
    "            language=\"he\"  # Hebrew is closest to Yiddish\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Speech generated: {output_file}\")\n",
    "        \n",
    "        # Play audio in Colab\n",
    "        from IPython.display import Audio, display\n",
    "        display(Audio(output_file))\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test speech generation\n",
    "test_phrases = [\n",
    "    \"◊©◊ë◊™ ◊©◊ú◊ï◊ù\",  # Shabbat Shalom\n",
    "    \"◊í◊ï◊ò ◊û◊ê◊®◊í◊ü\",  # Good morning\n",
    "    \"◊ê ◊ì◊ê◊†◊ß\",  # Thank you\n",
    "]\n",
    "\n",
    "for i, phrase in enumerate(test_phrases, 1):\n",
    "    print(f\"\\n--- Phrase {i}: {phrase} ---\")\n",
    "    output_file = f\"yiddish_output_{i}.wav\"\n",
    "    generate_yiddish_speech(phrase, output_file)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-section"
   },
   "source": [
    "## 5. Training Your Own Model\n",
    "\n",
    "Train a custom Yiddish TTS model with your data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prepare-training-data"
   },
   "source": [
    "def prepare_training_data(audio_dir=\"tts_segments/audio\", text_dir=\"tts_segments/text\"):\n",
    "    \"\"\"Prepare training data in LJSpeech format\"\"\"\n",
    "    \n",
    "    processor = YiddishTextProcessor()\n",
    "    metadata = []\n",
    "    \n",
    "    # Get all audio files\n",
    "    audio_files = sorted(Path(audio_dir).glob(\"*.wav\"))\n",
    "    \n",
    "    print(f\"Found {len(audio_files)} audio files\")\n",
    "    \n",
    "    for audio_file in audio_files:\n",
    "        # Get corresponding text file\n",
    "        text_file = Path(text_dir) / audio_file.stem\n",
    "        text_file = text_file.with_suffix('.txt')\n",
    "        \n",
    "        if text_file.exists():\n",
    "            # Read and normalize text\n",
    "            with open(text_file, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().strip()\n",
    "                normalized_text = processor.normalize_yiddish_text(text)\n",
    "                \n",
    "            # Add to metadata\n",
    "            rel_path = str(audio_file.absolute())\n",
    "            metadata.append(f\"{rel_path}|{normalized_text}|{normalized_text}\")\n",
    "            print(f\"Processed: {audio_file.name} -> {normalized_text[:50]}...\")\n",
    "    \n",
    "    # Save metadata file\n",
    "    metadata_file = \"yiddish_train_data.txt\"\n",
    "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(metadata))\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training data prepared: {metadata_file}\")\n",
    "    print(f\"Total samples: {len(metadata)}\")\n",
    "    \n",
    "    # Get unique characters\n",
    "    texts = [line.split('|')[1] for line in metadata]\n",
    "    unique_chars = processor.get_unique_chars(texts)\n",
    "    print(f\"Unique characters ({len(unique_chars)}): {''.join(unique_chars)}\")\n",
    "    \n",
    "    return metadata_file, unique_chars\n",
    "\n",
    "# Prepare data\n",
    "metadata_file, unique_chars = prepare_training_data()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "create-config"
   },
   "source": [
    "def create_training_config(unique_chars, output_path=\"./yiddish_tts_training/\"):\n",
    "    \"\"\"Create Tacotron2 configuration for Yiddish TTS\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"model\": \"tacotron2\",\n",
    "        \"run_name\": \"yiddish_tacotron2_colab\",\n",
    "        \"output_path\": output_path,\n",
    "        \n",
    "        \"datasets\": [{\n",
    "            \"name\": \"yiddish_dataset\",\n",
    "            \"path\": \"./\",\n",
    "            \"meta_file_train\": \"yiddish_train_data.txt\",\n",
    "            \"meta_file_val\": \"\",\n",
    "            \"formatter\": \"ljspeech\"\n",
    "        }],\n",
    "        \n",
    "        \"characters\": {\n",
    "            \"pad\": \"_\",\n",
    "            \"eos\": \"~\",\n",
    "            \"bos\": \"^\",\n",
    "            \"characters\": ''.join(unique_chars),\n",
    "            \"punctuations\": \"!\\\"'(),-.:;?[]\",\n",
    "            \"phonemes\": \"\",\n",
    "            \"is_unique\": True,\n",
    "            \"is_sorted\": True\n",
    "        },\n",
    "        \n",
    "        \"audio\": {\n",
    "            \"sample_rate\": 16000,\n",
    "            \"resample\": True,\n",
    "            \"do_trim_silence\": True,\n",
    "            \"trim_db\": 60,\n",
    "            \"mel_fmin\": 0,\n",
    "            \"mel_fmax\": 8000,\n",
    "            \"n_fft\": 1024,\n",
    "            \"hop_length\": 256,\n",
    "            \"win_length\": 1024,\n",
    "            \"n_mels\": 80,\n",
    "            \"preemphasis\": 0.97,\n",
    "            \"ref_level_db\": 20,\n",
    "            \"spec_gain\": 20\n",
    "        },\n",
    "        \n",
    "        \"model_params\": {\n",
    "            \"n_symbols\": len(unique_chars) + 3,  # +3 for pad, eos, bos\n",
    "            \"symbols_embedding_dim\": 512,\n",
    "            \"encoder_embedding_dim\": 512,\n",
    "            \"encoder_n_convolutions\": 3,\n",
    "            \"encoder_kernel_size\": 5,\n",
    "            \"attention_dim\": 128,\n",
    "            \"attention_location_n_filters\": 32,\n",
    "            \"attention_location_kernel_size\": 31,\n",
    "            \"decoder_rnn_dim\": 1024,\n",
    "            \"prenet_dim\": 256,\n",
    "            \"postnet_embedding_dim\": 512,\n",
    "            \"postnet_kernel_size\": 5,\n",
    "            \"postnet_n_convolutions\": 5,\n",
    "            \"gate_threshold\": 0.5\n",
    "        },\n",
    "        \n",
    "        \"train_config\": {\n",
    "            \"batch_size\": 16,  # Reduced for Colab\n",
    "            \"eval_batch_size\": 8,\n",
    "            \"epochs\": 100,\n",
    "            \"lr\": 0.001,\n",
    "            \"weight_decay\": 1e-6,\n",
    "            \"grad_clip\": 1.0,\n",
    "            \"print_step\": 10,\n",
    "            \"save_step\": 500,\n",
    "            \"log_step\": 100,\n",
    "            \"mixed_precision\": True,  # Enable for faster training\n",
    "            \"num_loader_workers\": 2,\n",
    "            \"num_eval_loader_workers\": 2\n",
    "        },\n",
    "        \n",
    "        \"test_sentences\": [\n",
    "            \"◊©◊ë◊™ ◊©◊ú◊ï◊ù ◊ê◊ï◊ü ◊ê ◊í◊ï◊ò◊ü ◊ò◊ê◊í ◊¶◊ï ◊ê◊ú◊¢\",\n",
    "            \"◊ê◊ô◊ö ◊ï◊ï◊ô◊ú ◊®◊¢◊ì◊ü ◊ê◊ï◊ô◊£ ◊ô◊ô◊ì◊ô◊© ◊û◊ô◊ò ◊ê◊ô◊ô◊ö\",\n",
    "            \"◊ì◊ê◊° ◊ê◊ô◊ñ ◊ê ◊ò◊¢◊°◊ò ◊§◊ï◊ü ◊û◊ô◊ô◊ü ◊†◊ô◊ô◊¢ ◊°◊ô◊°◊ò◊¢◊ù\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # Save config\n",
    "    config_file = \"yiddish_colab_config.json\"\n",
    "    with open(config_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Configuration saved: {config_file}\")\n",
    "    return config_file\n",
    "\n",
    "# Create config\n",
    "config_file = create_training_config(unique_chars)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "train-model"
   },
   "source": [
    "# Training with TTS library\n",
    "def train_tacotron2_model(config_file):\n",
    "    \"\"\"Train Tacotron2 model using the TTS library\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting Tacotron2 training...\")\n",
    "    print(\"This will take time. Monitor the progress below.\")\n",
    "    print(\"\\nTip: Training can be interrupted and resumed from checkpoints\\n\")\n",
    "    \n",
    "    # Run TTS training command\n",
    "    !python -m TTS.bin.train_tts \\\n",
    "        --config_path {config_file} \\\n",
    "        --coqpit.output_path \"./yiddish_tts_training/\" \\\n",
    "        --coqpit.datasets.0.path \"./\" \\\n",
    "        --coqpit.datasets.0.meta_file_train \"yiddish_train_data.txt\" \\\n",
    "        --coqpit.train_config.batch_size 8 \\\n",
    "        --coqpit.train_config.epochs 50\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed or interrupted!\")\n",
    "    print(\"Check ./yiddish_tts_training/ for checkpoints\")\n",
    "\n",
    "# Uncomment to start training\n",
    "# train_tacotron2_model(config_file)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "simplified-training"
   },
   "source": [
    "## 6. Simplified Training Script\n",
    "\n",
    "A more direct approach using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "simple-train"
   },
   "source": [
    "# Simplified training approach\n",
    "def simple_train_yiddish_tts():\n",
    "    \"\"\"Simplified training using existing multilingual model\"\"\"\n",
    "    \n",
    "    print(\"üéì Fine-tuning multilingual model for Yiddish...\")\n",
    "    \n",
    "    try:\n",
    "        # Use XTTS for fine-tuning (supports multilingual)\n",
    "        from TTS.api import TTS\n",
    "        \n",
    "        # Load pre-trained model\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
    "        \n",
    "        print(f\"Model loaded on {device}\")\n",
    "        \n",
    "        # Prepare your audio-text pairs\n",
    "        audio_files = list(Path(\"tts_segments/audio\").glob(\"*.wav\"))\n",
    "        \n",
    "        if len(audio_files) > 0:\n",
    "            print(f\"Found {len(audio_files)} audio files for fine-tuning\")\n",
    "            \n",
    "            # Note: XTTS v2 doesn't require explicit fine-tuning for new languages\n",
    "            # It can adapt using voice cloning\n",
    "            print(\"\\n‚úÖ Model ready for Yiddish generation!\")\n",
    "            print(\"XTTS v2 adapts to new languages through voice cloning.\")\n",
    "            print(\"Use your audio samples as reference voices.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No audio files found. Upload your data first.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nAlternative: Use the zero-shot generation approach above\")\n",
    "\n",
    "# Run simplified training\n",
    "simple_train_yiddish_tts()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utilities-section"
   },
   "source": [
    "## 7. Utilities & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "download-models"
   },
   "source": [
    "# Download trained models to local machine\n",
    "def download_models():\n",
    "    \"\"\"Download trained models and outputs\"\"\"\n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    # Create archive of training outputs\n",
    "    if os.path.exists(\"yiddish_tts_training\"):\n",
    "        print(\"Creating archive of training outputs...\")\n",
    "        shutil.make_archive(\"yiddish_tts_models\", 'zip', \"yiddish_tts_training\")\n",
    "        files.download(\"yiddish_tts_models.zip\")\n",
    "        print(\"‚úÖ Models downloaded!\")\n",
    "    \n",
    "    # Download generated audio files\n",
    "    for wav_file in Path(\".\").glob(\"yiddish_output*.wav\"):\n",
    "        files.download(str(wav_file))\n",
    "        print(f\"Downloaded: {wav_file}\")\n",
    "\n",
    "# Uncomment to download\n",
    "# download_models()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "test-phrases"
   },
   "source": [
    "# Interactive text-to-speech interface\n",
    "def interactive_tts():\n",
    "    \"\"\"Interactive interface for testing TTS\"\"\"\n",
    "    \n",
    "    print(\"üé§ Interactive Yiddish TTS\")\n",
    "    print(\"Enter Yiddish text to generate speech:\")\n",
    "    print(\"(Type 'quit' to exit)\\n\")\n",
    "    \n",
    "    while True:\n",
    "        text = input(\"Yiddish text: \").strip()\n",
    "        \n",
    "        if text.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        if text:\n",
    "            output_file = f\"output_{hash(text)}.wav\"\n",
    "            success = generate_yiddish_speech(text, output_file)\n",
    "            if success:\n",
    "                print(f\"‚úÖ Generated: {output_file}\\n\")\n",
    "        else:\n",
    "            print(\"Please enter some text\\n\")\n",
    "\n",
    "# Run interactive interface\n",
    "# interactive_tts()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips-section"
   },
   "source": [
    "## üìù Tips for Google Colab\n",
    "\n",
    "### GPU Usage\n",
    "- Always enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí T4 GPU\n",
    "- Monitor GPU usage: `!nvidia-smi`\n",
    "- Clear GPU memory if needed: `torch.cuda.empty_cache()`\n",
    "\n",
    "### Session Management\n",
    "- Colab sessions timeout after ~90 minutes of inactivity\n",
    "- Use Google Drive to persist models and data\n",
    "- Save checkpoints frequently during training\n",
    "\n",
    "### Memory Management\n",
    "- Reduce batch size if you get out-of-memory errors\n",
    "- Clear variables: `del variable_name`\n",
    "- Restart runtime if memory issues persist\n",
    "\n",
    "### Data Tips\n",
    "- Upload data as ZIP and extract for faster upload\n",
    "- Use Google Drive for large datasets\n",
    "- Keep audio files under 10 seconds for better training\n",
    "\n",
    "### Training Tips\n",
    "- Start with small epochs (10-20) to test\n",
    "- Monitor loss curves in TensorBoard\n",
    "- Save checkpoints every 500-1000 steps\n",
    "- Use mixed precision training for faster speed\n",
    "\n",
    "## üéØ Quick Start Commands\n",
    "\n",
    "```python\n",
    "# 1. Generate speech immediately (no training)\n",
    "generate_yiddish_speech(\"◊©◊ë◊™ ◊©◊ú◊ï◊ù\", \"output.wav\")\n",
    "\n",
    "# 2. Prepare your data\n",
    "metadata_file, unique_chars = prepare_training_data()\n",
    "\n",
    "# 3. Create configuration\n",
    "config_file = create_training_config(unique_chars)\n",
    "\n",
    "# 4. Train model (optional)\n",
    "train_tacotron2_model(config_file)\n",
    "```"
   ]
  }
 ]
}