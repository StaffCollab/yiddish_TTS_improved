{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header-section"
      },
      "source": [
        "# üé§ Yiddish TTS Training & Generation on Google Colab\n",
        "\n",
        "This notebook provides a complete setup for training and using Yiddish Text-to-Speech models on Google Colab with Python 3.12 compatibility.\n",
        "\n",
        "## Features\n",
        "- ‚úÖ Python 3.12 compatible\n",
        "- ‚úÖ GPU acceleration support\n",
        "- ‚úÖ Automatic dependency installation\n",
        "- ‚úÖ Data upload/download utilities\n",
        "- ‚úÖ Multiple training options (Tacotron2, XTTS)\n",
        "- ‚úÖ Immediate speech generation\n",
        "\n",
        "**Note**: Enable GPU in Runtime > Change runtime type > Hardware accelerator > GPU (T4 or better)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-section"
      },
      "source": [
        "## 1. Environment Setup & Dependencies\n",
        "\n",
        "Install all required packages with Python 3.12 compatibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "check-environment"
      },
      "source": [
        "# Check Python version and GPU availability\n",
        "import sys\n",
        "import subprocess\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Python version info: {sys.version_info}\")\n",
        "\n",
        "# Check for GPU\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError:\n",
        "    print(\"PyTorch not yet installed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install-dependencies"
      },
      "source": [
        "%%capture\n",
        "# Install system dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y libsndfile1 ffmpeg\n",
        "\n",
        "# Install Python packages with specific versions for Python 3.12\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# Install PyTorch with CUDA support\n",
        "!pip install torch>=2.1.0 torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install TTS and audio processing libraries\n",
        "!pip install TTS==0.22.0\n",
        "!pip install librosa>=0.10.0\n",
        "!pip install soundfile>=0.12.0\n",
        "!pip install numpy>=1.24.3,<2.0.0  # Cap numpy for compatibility\n",
        "!pip install pandas>=2.0.0\n",
        "!pip install scipy>=1.11.0\n",
        "!pip install matplotlib>=3.7.0\n",
        "!pip install scikit-learn>=1.3.0\n",
        "!pip install PyYAML>=6.0\n",
        "!pip install tqdm>=4.64.0\n",
        "!pip install tensorboard\n",
        "!pip install psutil\n",
        "\n",
        "# Install Whisper for alignment (optional)\n",
        "!pip install openai-whisper\n",
        "!pip install faster-whisper"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "verify-installation"
      },
      "source": [
        "# Verify installations\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import soundfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from TTS.api import TTS\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"TorchAudio: {torchaudio.__version__}\")\n",
        "print(f\"NumPy: {np.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "core-components-section"
      },
      "source": [
        "## 2. Core Components\n",
        "\n",
        "Define the essential classes and functions for Yiddish TTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiddish-text-processor"
      },
      "source": [
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "class YiddishTextProcessor:\n",
        "    \"\"\"Text processor for Yiddish (Hebrew script) for TTS training\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Hebrew character ranges\n",
        "        self.hebrew_chars = set()\n",
        "        # Main Hebrew block\n",
        "        for i in range(0x0590, 0x05FF):\n",
        "            self.hebrew_chars.add(chr(i))\n",
        "        # Hebrew presentation forms\n",
        "        for i in range(0xFB1D, 0xFB4F):\n",
        "            self.hebrew_chars.add(chr(i))\n",
        "        \n",
        "        # Essential punctuation and symbols\n",
        "        self.punctuation = \".,!?;:-()[]{}\\\"\\'`\"\n",
        "        self.allowed_chars = set(self.punctuation + \" \\n\\t\")\n",
        "        self.allowed_chars.update(\"0123456789\")\n",
        "        \n",
        "    def normalize_yiddish_text(self, text):\n",
        "        \"\"\"Normalize Yiddish text for TTS training\"\"\"\n",
        "        # Normalize Unicode\n",
        "        text = unicodedata.normalize('NFD', text)\n",
        "        \n",
        "        # Keep only Hebrew script characters, punctuation, and spaces\n",
        "        cleaned_chars = []\n",
        "        for char in text:\n",
        "            if char in self.hebrew_chars or char in self.allowed_chars:\n",
        "                cleaned_chars.append(char)\n",
        "            elif char.isspace():\n",
        "                cleaned_chars.append(' ')\n",
        "        \n",
        "        text = ''.join(cleaned_chars)\n",
        "        \n",
        "        # Clean up extra spaces\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "        \n",
        "        # Handle special Hebrew punctuation\n",
        "        text = text.replace('◊¥', '\"')  # Hebrew geresh\n",
        "        text = text.replace('◊≥', \"'\")  # Hebrew gershayim\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    def get_unique_chars(self, texts):\n",
        "        \"\"\"Get unique characters from all texts\"\"\"\n",
        "        unique_chars = set()\n",
        "        for text in texts:\n",
        "            normalized = self.normalize_yiddish_text(text)\n",
        "            unique_chars.update(normalized)\n",
        "        return sorted(list(unique_chars))\n",
        "\n",
        "print(\"‚úÖ YiddishTextProcessor class defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-section"
      },
      "source": [
        "## 3. Data Management\n",
        "\n",
        "Upload your data or use sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mount-drive"
      },
      "source": [
        "# Mount Google Drive (optional - for saving models and data)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create project directory in Drive\n",
        "project_dir = '/content/drive/MyDrive/yiddish_tts_project'\n",
        "os.makedirs(project_dir, exist_ok=True)\n",
        "print(f\"Project directory: {project_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upload-data"
      },
      "source": [
        "# Option 1: Upload your data files\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload your audio files and transcripts:\")\n",
        "print(\"Expected structure:\")\n",
        "print(\"  - Audio files: .wav format\")\n",
        "print(\"  - Text files: .txt format with matching names\")\n",
        "print(\"\\nClick 'Choose Files' below to upload:\")\n",
        "\n",
        "# Uncomment to enable file upload\n",
        "# uploaded = files.upload()\n",
        "# for filename in uploaded.keys():\n",
        "#     print(f'Uploaded: {filename}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "create-sample-data"
      },
      "source": [
        "# Option 2: Create sample training data\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "# Create directories\n",
        "os.makedirs('tts_segments/audio', exist_ok=True)\n",
        "os.makedirs('tts_segments/text', exist_ok=True)\n",
        "\n",
        "# Sample Yiddish texts\n",
        "sample_texts = [\n",
        "    \"◊©◊ë◊™ ◊©◊ú◊ï◊ù ◊ê◊ï◊ü ◊ê ◊í◊ï◊ò◊ü ◊ò◊ê◊í\",\n",
        "    \"◊ï◊ï◊ô ◊í◊ô◊ô◊ò ◊¢◊° ◊û◊ô◊ò ◊ê◊ô◊ô◊ö ◊î◊ô◊ô◊†◊ò\",\n",
        "    \"◊ê◊ô◊ö ◊ï◊ï◊ô◊ú ◊®◊¢◊ì◊ü ◊ê◊ï◊ô◊£ ◊ô◊ô◊ì◊ô◊©\",\n",
        "    \"◊ì◊ê◊° ◊ê◊ô◊ñ ◊ê ◊ò◊¢◊°◊ò ◊§◊ï◊ü ◊û◊ô◊ô◊ü ◊°◊ô◊°◊ò◊¢◊ù\",\n",
        "    \"◊ê ◊ì◊ê◊†◊ß ◊§◊ê◊® ◊ê◊ô◊ô◊¢◊® ◊¶◊ô◊ô◊ò\"\n",
        "]\n",
        "\n",
        "# Create dummy audio files (for demonstration)\n",
        "print(\"Creating sample data files...\")\n",
        "for i, text in enumerate(sample_texts, 1):\n",
        "    # Create dummy audio (1 second of silence)\n",
        "    audio = np.zeros(16000)  # 1 second at 16kHz\n",
        "    audio_path = f'tts_segments/audio/segment_{i:04d}.wav'\n",
        "    sf.write(audio_path, audio, 16000)\n",
        "    \n",
        "    # Save text\n",
        "    text_path = f'tts_segments/text/segment_{i:04d}.txt'\n",
        "    with open(text_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(text)\n",
        "    \n",
        "    print(f\"Created: {audio_path} with text: {text}\")\n",
        "\n",
        "print(\"\\n‚úÖ Sample data created!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generation-section"
      },
      "source": [
        "## 4. Immediate Speech Generation (No Training Required)\n",
        "\n",
        "Generate Yiddish speech immediately using pre-trained multilingual models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "generate-speech"
      },
      "source": [
        "def generate_yiddish_speech(text, output_file=\"yiddish_output.wav\", use_gpu=True):\n",
        "    \"\"\"Generate Yiddish speech from text using XTTS v2\"\"\"\n",
        "    \n",
        "    print(\"üé§ Yiddish Speech Generator\")\n",
        "    print(\"Using XTTS v2 for zero-shot voice cloning\")\n",
        "    print(f\"Text: {text}\")\n",
        "    print()\n",
        "    \n",
        "    try:\n",
        "        # Initialize TTS model\n",
        "        print(\"Loading XTTS v2 model (this may take a minute)...\")\n",
        "        device = \"cuda\" if torch.cuda.is_available() and use_gpu else \"cpu\"\n",
        "        tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "        print(f\"‚úì Model loaded on {device}!\")\n",
        "        \n",
        "        # Create a reference audio (using the first sample or a generated one)\n",
        "        reference_audio = \"tts_segments/audio/segment_0001.wav\"\n",
        "        if not os.path.exists(reference_audio):\n",
        "            print(\"Creating reference audio...\")\n",
        "            # Create a simple reference audio\n",
        "            ref_audio = np.random.randn(16000) * 0.1  # 1 second of noise\n",
        "            sf.write(reference_audio, ref_audio, 16000)\n",
        "        \n",
        "        print(\"Generating speech...\")\n",
        "        # Generate speech using Hebrew as the closest language\n",
        "        tts.tts_to_file(\n",
        "            text=text,\n",
        "            file_path=output_file,\n",
        "            speaker_wav=reference_audio,\n",
        "            language=\"he\"  # Hebrew is closest to Yiddish\n",
        "        )\n",
        "        \n",
        "        print(f\"‚úÖ Speech generated: {output_file}\")\n",
        "        \n",
        "        # Play audio in Colab\n",
        "        from IPython.display import Audio, display\n",
        "        display(Audio(output_file))\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error: {e}\")\n",
        "        return False\n",
        "\n",
        "# Test speech generation\n",
        "test_phrases = [\n",
        "    \"◊©◊ë◊™ ◊©◊ú◊ï◊ù\",  # Shabbat Shalom\n",
        "    \"◊í◊ï◊ò ◊û◊ê◊®◊í◊ü\",  # Good morning\n",
        "    \"◊ê ◊ì◊ê◊†◊ß\",  # Thank you\n",
        "]\n",
        "\n",
        "for i, phrase in enumerate(test_phrases, 1):\n",
        "    print(f\"\\n--- Phrase {i}: {phrase} ---\")\n",
        "    output_file = f\"yiddish_output_{i}.wav\"\n",
        "    generate_yiddish_speech(phrase, output_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-section"
      },
      "source": [
        "## 5. Training Your Own Model\n",
        "\n",
        "Train a custom Yiddish TTS model with your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prepare-training-data"
      },
      "source": [
        "def prepare_training_data(audio_dir=\"tts_segments/audio\", text_dir=\"tts_segments/text\"):\n",
        "    \"\"\"Prepare training data in LJSpeech format\"\"\"\n",
        "    \n",
        "    processor = YiddishTextProcessor()\n",
        "    metadata = []\n",
        "    \n",
        "    # Get all audio files\n",
        "    audio_files = sorted(Path(audio_dir).glob(\"*.wav\"))\n",
        "    \n",
        "    print(f\"Found {len(audio_files)} audio files\")\n",
        "    \n",
        "    for audio_file in audio_files:\n",
        "        # Get corresponding text file\n",
        "        text_file = Path(text_dir) / audio_file.stem\n",
        "        text_file = text_file.with_suffix('.txt')\n",
        "        \n",
        "        if text_file.exists():\n",
        "            # Read and normalize text\n",
        "            with open(text_file, 'r', encoding='utf-8') as f:\n",
        "                text = f.read().strip()\n",
        "                normalized_text = processor.normalize_yiddish_text(text)\n",
        "                \n",
        "            # Add to metadata\n",
        "            rel_path = str(audio_file.absolute())\n",
        "            metadata.append(f\"{rel_path}|{normalized_text}|{normalized_text}\")\n",
        "            print(f\"Processed: {audio_file.name} -> {normalized_text[:50]}...\")\n",
        "    \n",
        "    # Save metadata file\n",
        "    metadata_file = \"yiddish_train_data.txt\"\n",
        "    with open(metadata_file, 'w', encoding='utf-8') as f:\n",
        "        f.write('\\n'.join(metadata))\n",
        "    \n",
        "    print(f\"\\n‚úÖ Training data prepared: {metadata_file}\")\n",
        "    print(f\"Total samples: {len(metadata)}\")\n",
        "    \n",
        "    # Get unique characters\n",
        "    texts = [line.split('|')[1] for line in metadata]\n",
        "    unique_chars = processor.get_unique_chars(texts)\n",
        "    print(f\"Unique characters ({len(unique_chars)}): {''.join(unique_chars)}\")\n",
        "    \n",
        "    return metadata_file, unique_chars\n",
        "\n",
        "# Prepare data\n",
        "metadata_file, unique_chars = prepare_training_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "create-config"
      },
      "source": [
        "def create_training_config(unique_chars, output_path=\"./yiddish_tts_training/\"):\n",
        "    \"\"\"Create Tacotron2 configuration for Yiddish TTS\"\"\"\n",
        "    \n",
        "    config = {\n",
        "        \"model\": \"tacotron2\",\n",
        "        \"run_name\": \"yiddish_tacotron2_colab\",\n",
        "        \"output_path\": output_path,\n",
        "        \n",
        "        \"datasets\": [{\n",
        "            \"name\": \"yiddish_dataset\",\n",
        "            \"path\": \"./\",\n",
        "            \"meta_file_train\": \"yiddish_train_data.txt\",\n",
        "            \"meta_file_val\": \"\",\n",
        "            \"formatter\": \"ljspeech\"\n",
        "        }],\n",
        "        \n",
        "        \"characters\": {\n",
        "            \"pad\": \"_\",\n",
        "            \"eos\": \"~\",\n",
        "            \"bos\": \"^\",\n",
        "            \"characters\": ''.join(unique_chars),\n",
        "            \"punctuations\": \"!\\\"'(),-.:;?[]\",\n",
        "            \"phonemes\": \"\",\n",
        "            \"is_unique\": True,\n",
        "            \"is_sorted\": True\n",
        "        },\n",
        "        \n",
        "        \"audio\": {\n",
        "            \"sample_rate\": 16000,\n",
        "            \"resample\": True,\n",
        "            \"do_trim_silence\": True,\n",
        "            \"trim_db\": 60,\n",
        "            \"mel_fmin\": 0,\n",
        "            \"mel_fmax\": 8000,\n",
        "            \"n_fft\": 1024,\n",
        "            \"hop_length\": 256,\n",
        "            \"win_length\": 1024,\n",
        "            \"n_mels\": 80,\n",
        "            \"preemphasis\": 0.97,\n",
        "            \"ref_level_db\": 20,\n",
        "            \"spec_gain\": 20\n",
        "        },\n",
        "        \n",
        "        \"model_params\": {\n",
        "            \"n_symbols\": len(unique_chars) + 3,  # +3 for pad, eos, bos\n",
        "            \"symbols_embedding_dim\": 512,\n",
        "            \"encoder_embedding_dim\": 512,\n",
        "            \"encoder_n_convolutions\": 3,\n",
        "            \"encoder_kernel_size\": 5,\n",
        "            \"attention_dim\": 128,\n",
        "            \"attention_location_n_filters\": 32,\n",
        "            \"attention_location_kernel_size\": 31,\n",
        "            \"decoder_rnn_dim\": 1024,\n",
        "            \"prenet_dim\": 256,\n",
        "            \"postnet_embedding_dim\": 512,\n",
        "            \"postnet_kernel_size\": 5,\n",
        "            \"postnet_n_convolutions\": 5,\n",
        "            \"gate_threshold\": 0.5\n",
        "        },\n",
        "        \n",
        "        \"train_config\": {\n",
        "            \"batch_size\": 16,  # Reduced for Colab\n",
        "            \"eval_batch_size\": 8,\n",
        "            \"epochs\": 100,\n",
        "            \"lr\": 0.001,\n",
        "            \"weight_decay\": 1e-6,\n",
        "            \"grad_clip\": 1.0,\n",
        "            \"print_step\": 10,\n",
        "            \"save_step\": 500,\n",
        "            \"log_step\": 100,\n",
        "            \"mixed_precision\": True,  # Enable for faster training\n",
        "            \"num_loader_workers\": 2,\n",
        "            \"num_eval_loader_workers\": 2\n",
        "        },\n",
        "        \n",
        "        \"test_sentences\": [\n",
        "            \"◊©◊ë◊™ ◊©◊ú◊ï◊ù ◊ê◊ï◊ü ◊ê ◊í◊ï◊ò◊ü ◊ò◊ê◊í ◊¶◊ï ◊ê◊ú◊¢\",\n",
        "            \"◊ê◊ô◊ö ◊ï◊ï◊ô◊ú ◊®◊¢◊ì◊ü ◊ê◊ï◊ô◊£ ◊ô◊ô◊ì◊ô◊© ◊û◊ô◊ò ◊ê◊ô◊ô◊ö\",\n",
        "            \"◊ì◊ê◊° ◊ê◊ô◊ñ ◊ê ◊ò◊¢◊°◊ò ◊§◊ï◊ü ◊û◊ô◊ô◊ü ◊†◊ô◊ô◊¢ ◊°◊ô◊°◊ò◊¢◊ù\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    # Save config\n",
        "    config_file = \"yiddish_colab_config.json\"\n",
        "    with open(config_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(config, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Configuration saved: {config_file}\")\n",
        "    return config_file\n",
        "\n",
        "# Create config\n",
        "config_file = create_training_config(unique_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "train-model"
      },
      "source": [
        "# Training with TTS library\n",
        "def train_tacotron2_model(config_file):\n",
        "    \"\"\"Train Tacotron2 model using the TTS library\"\"\"\n",
        "    \n",
        "    print(\"üöÄ Starting Tacotron2 training...\")\n",
        "    print(\"This will take time. Monitor the progress below.\")\n",
        "    print(\"\\nTip: Training can be interrupted and resumed from checkpoints\\n\")\n",
        "    \n",
        "    # Run TTS training command\n",
        "    !python -m TTS.bin.train_tts \\\n",
        "        --config_path {config_file} \\\n",
        "        --coqpit.output_path \"./yiddish_tts_training/\" \\\n",
        "        --coqpit.datasets.0.path \"./\" \\\n",
        "        --coqpit.datasets.0.meta_file_train \"yiddish_train_data.txt\" \\\n",
        "        --coqpit.train_config.batch_size 8 \\\n",
        "        --coqpit.train_config.epochs 50\n",
        "    \n",
        "    print(\"\\n‚úÖ Training completed or interrupted!\")\n",
        "    print(\"Check ./yiddish_tts_training/ for checkpoints\")\n",
        "\n",
        "# Uncomment to start training\n",
        "# train_tacotron2_model(config_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "simplified-training"
      },
      "source": [
        "## 6. Simplified Training Script\n",
        "\n",
        "A more direct approach using PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "simple-train"
      },
      "source": [
        "# Simplified training approach\n",
        "def simple_train_yiddish_tts():\n",
        "    \"\"\"Simplified training using existing multilingual model\"\"\"\n",
        "    \n",
        "    print(\"üéì Fine-tuning multilingual model for Yiddish...\")\n",
        "    \n",
        "    try:\n",
        "        # Use XTTS for fine-tuning (supports multilingual)\n",
        "        from TTS.api import TTS\n",
        "        \n",
        "        # Load pre-trained model\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "        \n",
        "        print(f\"Model loaded on {device}\")\n",
        "        \n",
        "        # Prepare your audio-text pairs\n",
        "        audio_files = list(Path(\"tts_segments/audio\").glob(\"*.wav\"))\n",
        "        \n",
        "        if len(audio_files) > 0:\n",
        "            print(f\"Found {len(audio_files)} audio files for fine-tuning\")\n",
        "            \n",
        "            # Note: XTTS v2 doesn't require explicit fine-tuning for new languages\n",
        "            # It can adapt using voice cloning\n",
        "            print(\"\\n‚úÖ Model ready for Yiddish generation!\")\n",
        "            print(\"XTTS v2 adapts to new languages through voice cloning.\")\n",
        "            print(\"Use your audio samples as reference voices.\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No audio files found. Upload your data first.\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        print(\"\\nAlternative: Use the zero-shot generation approach above\")\n",
        "\n",
        "# Run simplified training\n",
        "simple_train_yiddish_tts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utilities-section"
      },
      "source": [
        "## 7. Utilities & Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "download-models"
      },
      "source": [
        "# Download trained models to local machine\n",
        "def download_models():\n",
        "    \"\"\"Download trained models and outputs\"\"\"\n",
        "    from google.colab import files\n",
        "    import shutil\n",
        "    \n",
        "    # Create archive of training outputs\n",
        "    if os.path.exists(\"yiddish_tts_training\"):\n",
        "        print(\"Creating archive of training outputs...\")\n",
        "        shutil.make_archive(\"yiddish_tts_models\", 'zip', \"yiddish_tts_training\")\n",
        "        files.download(\"yiddish_tts_models.zip\")\n",
        "        print(\"‚úÖ Models downloaded!\")\n",
        "    \n",
        "    # Download generated audio files\n",
        "    for wav_file in Path(\".\").glob(\"yiddish_output*.wav\"):\n",
        "        files.download(str(wav_file))\n",
        "        print(f\"Downloaded: {wav_file}\")\n",
        "\n",
        "# Uncomment to download\n",
        "# download_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "test-phrases"
      },
      "source": [
        "# Interactive text-to-speech interface\n",
        "def interactive_tts():\n",
        "    \"\"\"Interactive interface for testing TTS\"\"\"\n",
        "    \n",
        "    print(\"üé§ Interactive Yiddish TTS\")\n",
        "    print(\"Enter Yiddish text to generate speech:\")\n",
        "    print(\"(Type 'quit' to exit)\\n\")\n",
        "    \n",
        "    while True:\n",
        "        text = input(\"Yiddish text: \").strip()\n",
        "        \n",
        "        if text.lower() == 'quit':\n",
        "            break\n",
        "            \n",
        "        if text:\n",
        "            output_file = f\"output_{hash(text)}.wav\"\n",
        "            success = generate_yiddish_speech(text, output_file)\n",
        "            if success:\n",
        "                print(f\"‚úÖ Generated: {output_file}\\n\")\n",
        "        else:\n",
        "            print(\"Please enter some text\\n\")\n",
        "\n",
        "# Run interactive interface\n",
        "# interactive_tts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips-section"
      },
      "source": [
        "## üìù Tips for Google Colab\n",
        "\n",
        "### GPU Usage\n",
        "- Always enable GPU: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí T4 GPU\n",
        "- Monitor GPU usage: `!nvidia-smi`\n",
        "- Clear GPU memory if needed: `torch.cuda.empty_cache()`\n",
        "\n",
        "### Session Management\n",
        "- Colab sessions timeout after ~90 minutes of inactivity\n",
        "- Use Google Drive to persist models and data\n",
        "- Save checkpoints frequently during training\n",
        "\n",
        "### Memory Management\n",
        "- Reduce batch size if you get out-of-memory errors\n",
        "- Clear variables: `del variable_name`\n",
        "- Restart runtime if memory issues persist\n",
        "\n",
        "### Data Tips\n",
        "- Upload data as ZIP and extract for faster upload\n",
        "- Use Google Drive for large datasets\n",
        "- Keep audio files under 10 seconds for better training\n",
        "\n",
        "### Training Tips\n",
        "- Start with small epochs (10-20) to test\n",
        "- Monitor loss curves in TensorBoard\n",
        "- Save checkpoints every 500-1000 steps\n",
        "- Use mixed precision training for faster speed\n",
        "\n",
        "## üéØ Quick Start Commands\n",
        "\n",
        "```python\n",
        "# 1. Generate speech immediately (no training)\n",
        "generate_yiddish_speech(\"◊©◊ë◊™ ◊©◊ú◊ï◊ù\", \"output.wav\")\n",
        "\n",
        "# 2. Prepare your data\n",
        "metadata_file, unique_chars = prepare_training_data()\n",
        "\n",
        "# 3. Create configuration\n",
        "config_file = create_training_config(unique_chars)\n",
        "\n",
        "# 4. Train model (optional)\n",
        "train_tacotron2_model(config_file)\n",
        "```"
      ]
    }
  ]
}